{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "475a9451-98e0-45df-803c-2be07142ffe7",
   "metadata": {},
   "source": [
    "# Word Co-occurences\n",
    "\n",
    "To analyse co-occurences of topics of LGBTIQ datasets and visualize them. Useful links:\n",
    "- https://rainynotes.net/co-occurrence-matrix-visualization/\n",
    "- https://www.pingshiuanchua.com/blog/post/keyword-network-analysis-with-python-and-gephi\n",
    "- https://medium.com/data-analytics-at-nesta/how-to-create-network-visualisations-with-gephi-a-step-by-step-tutorial-e0743c49ec72\n",
    "- https://gephi.org/users/tutorial-layouts/\n",
    "\n",
    "Steps:\n",
    "- Write topics in a text file, one line per id/dataset\n",
    "- Count Vector Representation\n",
    "- Turn into matrix\n",
    "\n",
    "(Visualization of the co-occurrence matrix network is done by using Gephi, a open-source software to visualize network.)\n",
    "\n",
    "More on CountVectorizer:\n",
    "\n",
    "https://medium.com/swlh/understanding-count-vectorizer-5dd71530c1b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45717a5a-d758-408c-991d-58d75df32aeb",
   "metadata": {},
   "source": [
    "## Write topics in a text file, one line per id/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a5cbf6-19b2-41e4-b48e-5a0e74a9f4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klaukiaa\\AppData\\Local\\Temp\\ipykernel_4600\\213206260.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(str).groupby('ident')['topics_level_1'].apply(list).to_dict()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from slugify import slugify\n",
    "\n",
    "df = pd.read_csv(\"keywords_LGBTIQ_datasets.csv\", sep = ';', encoding=\"latin-1\")\n",
    "df = df.rename(columns={'id': 'ident'})\n",
    "\n",
    "# Read csv into dictionary with ident as keys and topics as values (in a list)\n",
    "# 2nd answer here: https://stackoverflow.com/questions/56062627/converting-csv-to-dictionary-with-one-column-as-keys-and-one-column-as-its-value \n",
    "df = df.applymap(str).groupby('ident')['topics_level_1'].apply(list).to_dict()\n",
    "#print(df)\n",
    "\n",
    "# Iterate over dictionary: https://realpython.com/iterate-through-dictionary-python/\n",
    "# Convert list to string: https://www.freecodecamp.org/news/python-list-to-string-how-to-convert-lists-in-python/ \n",
    "for key in df:\n",
    "    #print(df[key])\n",
    "    with open(\"output.txt\", 'w') as f:\n",
    "        for key in df:\n",
    "            string_list = [slugify(element) for element in df[key]]  # turns list into string and changes topics to dashes instead of spaces\n",
    "            res = list(map(lambda st: str.replace(st, \"-\", \"_\"), string_list))   # Changes - to _ (necessary to be treated as one word later)\n",
    "            delimiter = \" \"\n",
    "            result_string = delimiter.join(res)\n",
    "            f.write('%s,\\n' % (result_string)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d42c7-e9f9-403d-ba9b-1670b8fb12e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Count Vector Representation\n",
    "\n",
    "CountVectorizer is used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text.\n",
    "\n",
    "https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed6afff-484e-48e1-b658-d9f52004cb85",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a10d419-33d6-4e59-924e-351d621dc35b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14_social_stratification_and_groupings': 13, '16_society_and_culture': 15, '08_law_crime_and_legal_systems': 7, '04_health': 3, '19_other': 18, '07_labour_and_employment': 6, '11_politics': 10, '05_history': 4, '01_demography_population_vital_statistics_and_censuses': 0, '13_science_and_technology': 12, '03_education': 2, '06_housing_and_land_use': 5, '02_economics': 1, '09_media_communication_and_language': 8, '15_social_welfare_policy_and_systems': 14, '18_transport_and_travel': 17, '17_trade_industry_and_markets': 16, '12_psychology': 11, '10_natural_environment': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "f = open(\"output.txt\", \"r\")\n",
    "data = f.read()\n",
    "data_into_list = data.split(\",\\n\")\n",
    "#print(data_into_list) \n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(data_into_list)\n",
    "\n",
    "print(count_vect.vocabulary_)\n",
    "# --> Unique words along with indeces (= words sorted alphabetically, index is the place in the sorted list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad28c0a-30e1-456f-b002-76edcbcdcc3d",
   "metadata": {},
   "source": [
    "### Derive vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02d504d-4e3f-4a3b-b10c-dd1713d35338",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   30   12  170    2   24   85   34   18    4   11    4    2  131\n",
      "    14  109    8    4   35]\n",
      " [  30    0   45  303    0   91  292  108   37    2   28   10    5  564\n",
      "    47  345   36   14   63]\n",
      " [  12   45    0  112    1   36  117   49   26    4   15    6    0  212\n",
      "    12  112   16    4   34]\n",
      " [ 170  303  112    0    3  260  824  300  272   80   59   46   47 1774\n",
      "   174 1565   24   45  515]\n",
      " [   2    0    1    3    0    0    6   14    0    0    5    0    0   15\n",
      "     0    5    0    0  141]\n",
      " [  24   91   36  260    0    0  221   83   39    4   23    9    3  380\n",
      "    33  244   28   10   54]\n",
      " [  85  292  117  824    6  221    0  271  117   14   84   32   10 1195\n",
      "   115  728  100   35  246]\n",
      " [  34  108   49  300   14   83  271    0   57    8   39   13    1  519\n",
      "    31  293   36   10   96]\n",
      " [  18   37   26  272    0   39  117   57    0   12   15    9    0  270\n",
      "     9  165   12    3   54]\n",
      " [   4    2    4   80    0    4   14    8   12    0    2    2    0   42\n",
      "     0   30    0    0   14]\n",
      " [  11   28   15   59    5   23   84   39   15    2    0    4    0  125\n",
      "     9   67   12    3   32]\n",
      " [   4   10    6   46    0    9   32   13    9    2    4    0    0   55\n",
      "     3   32    4    1   11]\n",
      " [   2    5    0   47    0    3   10    1    0    0    0    0    0   12\n",
      "     4   20    0    1    5]\n",
      " [ 131  564  212 1774   15  380 1195  519  270   42  125   55   12    0\n",
      "   134 1629  136   42  351]\n",
      " [  14   47   12  174    0   33  115   31    9    0    9    3    4  134\n",
      "     0  127   12    7   28]\n",
      " [ 109  345  112 1565    5  244  728  293  165   30   67   32   20 1629\n",
      "   127    0   68   36  274]\n",
      " [   8   36   16   24    0   28  100   36   12    0   12    4    0  136\n",
      "    12   68    0    4   16]\n",
      " [   4   14    4   45    0   10   35   10    3    0    3    1    1   42\n",
      "     7   36    4    0    8]\n",
      " [  35   63   34  515  141   54  246   96   54   14   32   11    5  351\n",
      "    28  274   16    8    0]]\n"
     ]
    }
   ],
   "source": [
    "# Encode the Document\n",
    "vector = count_vect.fit_transform(data_into_list)\n",
    "Xc = (vector.T * vector) # Transposed matrix multiplied with original matrix\n",
    "Xc.setdiag(0) # set the diagonals to be zeroes as it's pointless to be 1\n",
    "\n",
    "# Summarizing the Encoded Texts\n",
    "print(Xc.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946b60b-f89f-4625-8aa2-aa9f2ca988d9",
   "metadata": {},
   "source": [
    "## Create matrix for Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e74cc80-8c8c-40a9-bcbc-86cf3124dfac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = count_vect.get_feature_names_out() # This are the entity names (i.e. keywords)\n",
    "df = pd.DataFrame(data = Xc.toarray(), columns = names, index = names)\n",
    "\n",
    "dict = {'01_demography_population_vital_statistics_and_censuses': 'Demography',\n",
    "        '02_economics': 'Economics',\n",
    "        '03_education': 'Education',\n",
    "        '04_health': 'Health',\n",
    "        '05_history': 'History',\n",
    "        '06_housing_and_land_use': 'Housing and land use',\n",
    "        '07_labour_and_employment': 'Labour and employment',\n",
    "        '08_law_crime_and_legal_systems': 'Law, crime, and legal systems',\n",
    "        '09_media_communication_and_language': 'Media, communication, and language',\n",
    "        '10_natural_environment': 'Natural environment',\n",
    "        '11_politics': 'Politics',\n",
    "        '12_psychology': 'Psychology',\n",
    "        '13_science_and_technology': 'Science and technology',\n",
    "        '14_social_stratification_and_groupings': 'Social stratification and groupings',\n",
    "        '15_social_welfare_policy_and_systems': 'Social welfare policy and systems',\n",
    "        '16_society_and_culture': 'Society and culture',\n",
    "        '17_trade_industry_and_markets': 'Trade, industry, and markets',\n",
    "        '18_transport_and_travel': 'Transport and travel',\n",
    "        '19_other': 'Other'}\n",
    "\n",
    "# Rename header and index\n",
    "df.rename(columns=dict, inplace=True)\n",
    "df.rename(index=dict, inplace=True)\n",
    "\n",
    "df.to_csv('to_gephi.csv', sep = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
